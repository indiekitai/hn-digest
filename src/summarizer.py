"""
AI Summarizer - Generate Chinese digest from HN stories
"""
import os
from dataclasses import dataclass
import anthropic
import httpx

from .scraper import Story


@dataclass
class DigestedStory:
    story: Story
    summary_zh: str
    category: str  # tech, ai, startup, programming, etc.
    importance: int  # 1-5 scale


@dataclass
class DailyDigest:
    date: str
    stories: list[DigestedStory]
    intro: str  # AI-generated intro paragraph
    

async def fetch_article_content(url: str, max_chars: int = 8000) -> str | None:
    """Fetch article content for better summarization."""
    if not url:
        return None
    try:
        async with httpx.AsyncClient(timeout=15.0, follow_redirects=True) as client:
            resp = await client.get(url, headers={
                "User-Agent": "Mozilla/5.0 (compatible; HNDigestBot/1.0)"
            })
            if resp.status_code == 200:
                # Very basic extraction - just get text
                text = resp.text[:max_chars]
                return text
    except Exception:
        pass
    return None


def create_summarizer(api_key: str | None = None) -> "Summarizer":
    """Create a summarizer instance."""
    key = api_key or os.getenv("ANTHROPIC_API_KEY")
    if not key:
        raise ValueError("ANTHROPIC_API_KEY required")
    return Summarizer(key)


class Summarizer:
    def __init__(self, api_key: str):
        self.client = anthropic.Anthropic(api_key=api_key)
    
    def summarize_stories(self, stories: list[Story], max_stories: int = 10) -> DailyDigest:
        """Generate a daily digest from stories."""
        # Sort by score and take top N
        sorted_stories = sorted(stories, key=lambda s: s.score, reverse=True)[:max_stories]
        
        # Build prompt
        stories_text = "\n\n".join([
            f"### {i+1}. {s.title}\n"
            f"Score: {s.score} | Comments: {s.descendants} | By: {s.by}\n"
            f"URL: {s.url or s.hn_url}\n"
            f"{'Text: ' + s.text[:500] + '...' if s.text else ''}"
            for i, s in enumerate(sorted_stories)
        ])
        
        prompt = f"""ä½ æ˜¯ä¸€ä½èµ„æ·±ç§‘æŠ€ç¼–è¾‘ï¼Œè´Ÿè´£ä¸ºä¸­å›½å¼€å‘è€…ç¼–å†™æ¯æ—¥ Hacker News ç²¾é€‰ã€‚

ä»Šæ—¥ Top Stories:
{stories_text}

è¯·å®Œæˆä»¥ä¸‹ä»»åŠ¡ï¼š

1. ä¸ºæ¯ç¯‡æ–‡ç« å†™ä¸€ä¸ªç®€æ´çš„ä¸­æ–‡æ‘˜è¦ï¼ˆ2-3å¥è¯ï¼‰ï¼Œè§£é‡Šä¸ºä»€ä¹ˆè¿™ç¯‡æ–‡ç« å€¼å¾—å…³æ³¨
2. ç»™æ¯ç¯‡æ–‡ç« åˆ†ç±»ï¼štech/ai/startup/programming/career/other
3. ç»™æ¯ç¯‡æ–‡ç« æ‰“é‡è¦æ€§åˆ†æ•° 1-5ï¼ˆ5æœ€é‡è¦ï¼‰
4. å†™ä¸€æ®µä»Šæ—¥ç§‘æŠ€åœˆæ€»ç»“ä½œä¸ºå¼€åœºç™½ï¼ˆ3-4å¥è¯ï¼‰

è¾“å‡ºæ ¼å¼ï¼ˆJSONï¼‰ï¼š
{{
  "intro": "ä»Šæ—¥å¼€åœºç™½...",
  "stories": [
    {{
      "index": 1,
      "summary_zh": "ä¸­æ–‡æ‘˜è¦...",
      "category": "ai",
      "importance": 5
    }}
  ]
}}

åªè¾“å‡º JSONï¼Œä¸è¦å…¶ä»–å†…å®¹ã€‚"""

        response = self.client.messages.create(
            model="claude-sonnet-4-20250514",
            max_tokens=2000,
            messages=[{"role": "user", "content": prompt}]
        )
        
        # Parse response
        import json
        text = response.content[0].text.strip()
        # Handle markdown code blocks
        if text.startswith("```"):
            text = text.split("```")[1]
            if text.startswith("json"):
                text = text[4:]
        
        data = json.loads(text)
        
        # Build digest
        digested = []
        for item in data["stories"]:
            idx = item["index"] - 1
            if 0 <= idx < len(sorted_stories):
                digested.append(DigestedStory(
                    story=sorted_stories[idx],
                    summary_zh=item["summary_zh"],
                    category=item["category"],
                    importance=item["importance"],
                ))
        
        from datetime import date
        return DailyDigest(
            date=date.today().isoformat(),
            stories=digested,
            intro=data["intro"],
        )


def format_digest_markdown(digest: DailyDigest) -> str:
    """Format digest as Markdown."""
    lines = [
        f"# ğŸŠ HN æ¯æ—¥ç²¾é€‰ | {digest.date}",
        "",
        digest.intro,
        "",
        "---",
        "",
    ]
    
    # Group by importance
    important = [s for s in digest.stories if s.importance >= 4]
    others = [s for s in digest.stories if s.importance < 4]
    
    if important:
        lines.append("## ğŸ”¥ ä»Šæ—¥å¿…è¯»")
        lines.append("")
        for ds in important:
            lines.append(f"### {ds.story.title}")
            lines.append(f"ğŸ“Š {ds.story.score} åˆ† | ğŸ’¬ {ds.story.descendants} è¯„è®º | ğŸ·ï¸ {ds.category}")
            lines.append("")
            lines.append(ds.summary_zh)
            lines.append("")
            lines.append(f"ğŸ”— [åŸæ–‡]({ds.story.url or ds.story.hn_url}) | [HN è®¨è®º]({ds.story.hn_url})")
            lines.append("")
    
    if others:
        lines.append("## ğŸ“° å…¶ä»–å€¼å¾—ä¸€çœ‹")
        lines.append("")
        for ds in others:
            lines.append(f"- **{ds.story.title}** ({ds.story.score}åˆ†)")
            lines.append(f"  {ds.summary_zh}")
            lines.append(f"  [é“¾æ¥]({ds.story.url or ds.story.hn_url})")
            lines.append("")
    
    return "\n".join(lines)


def format_digest_telegram(digest: DailyDigest) -> str:
    """Format digest for Telegram (no markdown tables)."""
    lines = [
        f"ğŸŠ <b>HN æ¯æ—¥ç²¾é€‰ | {digest.date}</b>",
        "",
        digest.intro,
        "",
    ]
    
    for i, ds in enumerate(digest.stories[:5], 1):
        emoji = "ğŸ”¥" if ds.importance >= 4 else "ğŸ“°"
        lines.append(f"{emoji} <b>{i}. {ds.story.title}</b>")
        lines.append(f"   ğŸ“Š {ds.story.score} | ğŸ’¬ {ds.story.descendants} | ğŸ·ï¸ {ds.category}")
        lines.append(f"   {ds.summary_zh}")
        url = ds.story.url or ds.story.hn_url
        lines.append(f'   <a href="{url}">åŸæ–‡</a> | <a href="{ds.story.hn_url}">è®¨è®º</a>')
        lines.append("")
    
    if len(digest.stories) > 5:
        lines.append(f"...è¿˜æœ‰ {len(digest.stories) - 5} ç¯‡ï¼Œå®Œæ•´ç‰ˆè§ç½‘é¡µ")
    
    return "\n".join(lines)
